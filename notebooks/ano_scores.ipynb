{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfkl = tfk.layers\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.flows import Flow, MAF, CondMAF\n",
    "\n",
    "# class CondMAF(Flow):\n",
    "#     \"\"\"Masked Autoregressive Flow model.\n",
    "    \n",
    "#     Based a chain of trainable 'Bijector' objects from the \n",
    "#     'tensorflow-probability' module\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_dims, n_layers, units, name=None, dtype='float32'):\n",
    "#         \"\"\"Creates a MAF object.\n",
    "\n",
    "#         Args:\n",
    "#           n_dims: The dimensionality of input (and output) data\n",
    "#           n_layers: The number of 'AutoregressiveNetwork' bijectors\n",
    "#           units: The units of every 'AutoregressiveNetwork' object\n",
    "#           name: String argument passed to the 'Model' parent class constructor\n",
    "#           dtype: The type of data used by the network\n",
    "#         \"\"\" \n",
    "#         super(CondMAF, self).__init__(name=name, dtype=dtype)\n",
    "\n",
    "#         # Create the necessary 'AutoregressiveNetwork' bijectors\n",
    "#         self.mades = [tfb.AutoregressiveNetwork(\n",
    "#                             params=2, \n",
    "#                             hidden_units=units,\n",
    "#                             input_order=self._input_order(i, n_layers),\n",
    "#                             activation='tanh',\n",
    "#                             event_shape=(n_dims,),\n",
    "#                             conditional=True,\n",
    "#                             conditional_event_shape=(1,))\n",
    "#                      for i \n",
    "#                      in range(n_layers)]\n",
    "\n",
    "#         \"\"\" Make a chain of MAF bijectors passing the previously defined\n",
    "#         MADEs as the 'shift_and_log_scale_fn' \"\"\"\n",
    "#         self.bijectors = [tfb.MaskedAutoregressiveFlow(made, name=f'made{i}')\n",
    "#                           for i, made \n",
    "#                           in enumerate(self.mades)]\n",
    "#         self.chain = tfb.Chain(self.bijectors)\n",
    "#         self.made_names = [f'made{i}' for i in range(n_layers)]\n",
    "\n",
    "#         \"\"\"Use bijector chain to make a TransformedDistribution starting \n",
    "#         from a Normal base distribution.\"\"\" \n",
    "#         self.distribution = tfd.TransformedDistribution(\n",
    "#                 distribution=tfd.Sample(tfd.Normal(loc=0., scale=1.),\n",
    "#                                         sample_shape=[n_dims]),\n",
    "#                 bijector=self.chain)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         \"\"\"Returns the log likelihood of the input samples\"\"\"\n",
    "#         x_ = x[0]\n",
    "#         c_ = x[1]\n",
    "#         kwargs = {key:{'conditional_input': c_}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.distribution.log_prob(x_, bijector_kwargs=kwargs)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Returns the input transformed by the forward bijector chain.\"\"\"\n",
    "#         x_ = x[0]\n",
    "#         c_ = x[1].reshape(-1,1)\n",
    "#         kwargs = {key:{'conditional_input': c_}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.chain(x_, **kwargs).numpy()\n",
    "\n",
    "#     def inverse(self, y):\n",
    "#         \"\"\"Returns the input transformed by the inverse bijector chain.\"\"\"\n",
    "#         y_ = y[0]\n",
    "#         c_ = y[1].reshape(-1,1)\n",
    "#         kwargs = {key:{'conditional_input': c_}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.chain.inverse(y_, **kwargs).numpy()\n",
    "\n",
    "#     def sample(self, c, sample_shape=()):\n",
    "#         \"\"\"Returns a sample from the transformed distribution\"\"\"\n",
    "#         kwargs = {key:{'conditional_input': c.reshape(-1,1)}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.distribution.sample(sample_shape, \n",
    "#                                         bijector_kwargs=kwargs).numpy()\n",
    "\n",
    "#     def forward_log_det_jacobian(self, x, event_ndims=1):\n",
    "#         \"\"\"Log of the Jacobian determinant for a forwad transofrmation.\"\"\"\n",
    "#         x_ = x[0]\n",
    "#         c_ = x[1].reshape(-1,1)\n",
    "#         kwargs = {key:{'conditional_input': c_}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.chain.forward_log_det_jacobian(x_, event_ndims=1,\n",
    "#                                             **kwargs).numpy()\n",
    "\n",
    "#     def inverse_log_det_jacobian(self, x, event_ndims=1):\n",
    "#         \"\"\"Log of the Jacobian determinant for an inverse transofrmation.\"\"\"\n",
    "#         x_ = x[0]\n",
    "#         c_ = x[1].reshape(-1,1)\n",
    "#         kwargs = {key:{'conditional_input': c_}\n",
    "#                   for key \n",
    "#                   in self.made_names}\n",
    "#         return self.chain.inverse_log_det_jacobian(x_, event_ndims=1,\n",
    "#                                             **kwargs).numpy()\n",
    "\n",
    "#     def _input_order(self, i, n_layers):\n",
    "#         \"\"\"Determine input order of a Layer given its index number\"\"\"\n",
    "#         order = 'random'\n",
    "#         if i == 0:\n",
    "#             order = 'left-to-right'\n",
    "#         elif i == n_layers-1:\n",
    "#             order = 'right-to-left'\n",
    "#         return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"tensorflow\", tf.__version__)\n",
    "print(\"tensorflow-probability\", tfp.__version__)\n",
    "print(\"Available devices:\", *[dev[1] for dev in devices])\n",
    "\n",
    "# SEED = 42\n",
    "# np.random.seed(SEED) \n",
    "# tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, dump_json\n",
    "\n",
    "from loaders.LHCO import LhcoRnDLoader\n",
    "\n",
    "loader = LhcoRnDLoader.from_json(\"../configs/loader/default_rnd.json\")\n",
    "dataset_cfg = load_json(\"../configs/loader/default_dataset.json\")\n",
    "dataset = loader.make_full_dataset(**dataset_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import feature_plots\n",
    "\n",
    "fig = feature_plots(dataset['x_train'], 'all')\n",
    "fig.update_layout(title=\"Training features transformed\")\n",
    "fig.show('svg')\n",
    "fig = feature_plots(dataset['x_test'], 'all', color='coral')\n",
    "fig.update_layout(title=\"Testing features transformed\")\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from density import GMM, ConvKDE\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"presentation\"\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "gmm=GMM(n_components=200, covariance_type='full')\n",
    "gmm.fit(dataset[\"mjj_train\"])\n",
    "y_gmm = gmm.evaluate(dataset[\"mjj_train\"])\n",
    "\n",
    "fftkde = ConvKDE()\n",
    "fftkde.fit(dataset[\"mjj_train\"])#, range=(1500, 8000)) \n",
    "y_kde = fftkde.evaluate(dataset[\"mjj_train\"])\n",
    "\n",
    "w_gmm = gmm.get_weights(dataset['mjj_train'])\n",
    "w_kde = fftkde.get_weights(dataset['mjj_train'])\n",
    "\n",
    "w_kde_valid = fftkde.get_weights(dataset[\"mjj_valid\"])\n",
    "w_gmm_valid = gmm.get_weights(dataset[\"mjj_valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ref = np.linspace(1500, 8000, 1701)\n",
    "y_gmm = gmm.evaluate(x_ref)\n",
    "y_kde = fftkde.evaluate(x_ref)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_ref, y=y_gmm, mode='lines', name='GMM',\n",
    "                         line={'color': 'greenyellow', 'width': 2, 'dash': 'dot'}))\n",
    "fig.add_trace(go.Scatter(x=x_ref, y=y_kde, mode='lines', name='FFTKDE',\n",
    "                         line={'color': 'indianred', 'width': 2, 'dash': 'dash'}))\n",
    "fig.add_trace(go.Histogram(x=dataset[\"mjj_train\"], nbinsx=600, histnorm='probability density', \n",
    "                           marker_color='steelblue', name='Histnorm'))\n",
    "fig.update_layout(\n",
    "    title_text='Dijet mass distribution and density estimation',\n",
    "    xaxis_title_text=r'$$m_{jj}$$',\n",
    "    yaxis_title_text=r'density',\n",
    ")\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = 'mjj_train'\n",
    "w_gmm = gmm.get_weights(dataset[data_key])\n",
    "w_kde = fftkde.get_weights(dataset[data_key])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(x=dataset[data_key], y=w_gmm, \n",
    "                           mode='markers', name='GMM', opacity=0.8,\n",
    "                           marker=dict(color='greenyellow',symbol='diamond'))\n",
    "            )\n",
    "fig.add_trace(go.Scattergl(x=dataset[data_key], y=w_kde, \n",
    "                           mode='markers', name='FFTKDE', opacity=0.8,\n",
    "                           marker=dict(color='indianred',symbol='star-square'))\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title_text='Weights relative to dijetmass scatter plot',\n",
    "    xaxis_title_text=r'$$m_{jj}$$',\n",
    "    yaxis_title_text=r'weight',\n",
    ")\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling $m_{jj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "c_train = scaler.fit_transform(dataset['mjj_train'].reshape(-1,1))\n",
    "c_valid = scaler.transform(dataset['mjj_valid'].reshape(-1,1))\n",
    "c_test = scaler.transform(dataset['mjj_test'].reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.autoencoder import DenseAutoencoder\n",
    "# ae_config = {\n",
    "#     'input_dim':47, \n",
    "#     'encoding_dim':10, \n",
    "#     'units_list':[30, 20, 15],\n",
    "#     'weight_reg':tfk.regularizers.l1(1e-6),\n",
    "#     'output_activation':tf.nn.sigmoid\n",
    "# }\n",
    "# ae_optimizer = tfk.optimizers.Adam(lr=0.05)\n",
    "# ae = DenseAutoencoder(**ae_config)\n",
    "# ae.compile(ae_optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.autoencoder import DenseAutoencoder\n",
    "from models.nn import PaeBuilder\n",
    "builder = PaeBuilder()\n",
    "\n",
    "ae_config = {\n",
    "    'input_dim':47, \n",
    "    'encoding_dim':10, \n",
    "    'units':[30, 20, 15],\n",
    "    'weight_reg':tfk.regularizers.l1(1e-6),\n",
    "    'output_activation':tf.nn.sigmoid\n",
    "}\n",
    "nf_config = {\n",
    "    'n_dims':10, \n",
    "    'n_layers':5, \n",
    "    'units':[32 for i in range(4)]\n",
    "}\n",
    "optimizer_ae = {\n",
    "    'lr': 0.05\n",
    "}\n",
    "optimizer_nf = {\n",
    "    'lr': 0.005\n",
    "}\n",
    "\n",
    "builder.make_ae_model(DenseAutoencoder, ae_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_ae)\n",
    "builder.make_nf_model(MAF, nf_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_nf)\n",
    "builder.compile_ae()\n",
    "builder.compile_nf()\n",
    "pae = builder.pae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_ones = np.ones_like(w_gmm)\n",
    "w_ones_valid = np.ones_like(w_gmm_valid)\n",
    "\n",
    "ae_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':180,\n",
    "    'sample_weight':w_gmm,\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"],w_gmm_valid),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=10,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "\n",
    "nf_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':100,\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"]),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    %time pae.fit(dataset[\"x_train\"],ae_train,nf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = pae.ae\n",
    "nf = pae.nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_true = pae.ae.encode(dataset['x_train'])\n",
    "z_sample = pae.nf.sample(dataset['x_train'].shape[0])\n",
    "\n",
    "from plotting import latent_space_plot\n",
    "\n",
    "fig = latent_space_plot(z_true, z_sample)\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = CondMAF(**nf_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_optimizer =tfk.optimizers.Adam(lr=0.005)\n",
    "cnf.compile(optimizer=cnf_optimizer, loss=lambda _, log_p: -log_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ae_history = ae.fit(\n",
    "#     x=dataset['x_train'],\n",
    "#     y=dataset['x_train'],\n",
    "#     batch_size=200,\n",
    "#     epochs=180,\n",
    "#     sample_weight=w_kde,\n",
    "#     validation_data=(dataset[\"x_valid\"],dataset[\"x_valid\"],w_kde_valid),\n",
    "#     callbacks=tfk.callbacks.ReduceLROnPlateau(\n",
    "#         factor=0.2,\n",
    "#         patience=10,\n",
    "#         verbose=1\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = ae.encode(dataset['x_train'])\n",
    "z_valid = ae.encode(dataset['x_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnf_history = cnf.fit(x=[z_train, c_train],\n",
    "        y=np.zeros((160000,0)),\n",
    "        batch_size=200,\n",
    "        epochs=100,\n",
    "        validation_data= ([z_valid, c_valid] ,np.zeros(z_valid.shape[0])),\n",
    "        callbacks=tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1))\n",
    "\n",
    "# nf_history = nf.fit(x=z_train,\n",
    "#         y=np.zeros((160000,0)),\n",
    "#         batch_size=200,\n",
    "#         epochs=100,\n",
    "#         validation_data= (z_valid ,np.zeros(z_valid.shape[0])),\n",
    "#         callbacks=tfk.callbacks.ReduceLROnPlateau(\n",
    "#         factor=0.2,\n",
    "#         patience=5,\n",
    "#         verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import latent_space_plot\n",
    "\n",
    "\n",
    "cz_sample = cnf.sample(c_train, (c_train.shape[0],))\n",
    "\n",
    "fig = latent_space_plot(z_train, cz_sample)\n",
    "fig.show('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmjj_train = fftkde.evaluate(dataset['mjj_train'])\n",
    "pmjj = fftkde.evaluate(dataset['mjj_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmjj[pmjj<=0] = 1e-8\n",
    "pmjj_train[pmjj_train<=0] = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test = ae.encode(dataset['x_test'])\n",
    "\n",
    "pz = nf(z_test).numpy()\n",
    "cpz = cnf([z_test, c_test]).numpy()\n",
    "pzr = pz-np.log(pmjj)\n",
    "cpzr = cpz-np.log(pmjj)\n",
    "\n",
    "pz_train = -nf(z_train).numpy()\n",
    "cpz_train = -cnf([z_train, c_train]).numpy()\n",
    "pzr_train = pz_train-np.log(pmjj_train)\n",
    "cpzr_train = cpz_train-np.log(pmjj_train)\n",
    "\n",
    "\n",
    "x_true = dataset['x_valid']\n",
    "x_reco = ae(x_true)\n",
    "sigma = np.mean(np.square(x_true-x_reco), axis=0)\n",
    "\n",
    "### train_data\n",
    "x_true = dataset['x_train']\n",
    "x_reco = ae(x_true)\n",
    "mse_train = np.mean(np.square(x_true-x_reco), axis=1)\n",
    "nmse_train = np.dot(np.square(x_true-x_reco),sigma**(-1))\n",
    "\n",
    "reco_error = np.square(x_true-x_reco)\n",
    "z = z_train\n",
    "byz = nf.inverse(z)\n",
    "detJ = nf.inverse_log_det_jacobian(z)\n",
    "apae_train = -0.5*np.dot(reco_error,sigma**(-1)) - \\\n",
    "        0.5*np.linalg.norm(byz,axis=1)**2 + detJ\n",
    "\n",
    "byz = cnf.inverse([z, c_train])\n",
    "detJ = cnf.inverse_log_det_jacobian([z, c_train])\n",
    "cpae_train = -0.5*np.dot(reco_error,sigma**(-1)) - \\\n",
    "        0.5*np.linalg.norm(byz,axis=1)**2 + detJ\n",
    "\n",
    "### test data\n",
    "x_true = dataset['x_test']\n",
    "x_reco = ae(x_true)\n",
    "mse = np.mean(np.square(x_true-x_reco), axis=1)\n",
    "nmse = np.dot(np.square(x_true-x_reco),sigma**(-1))\n",
    "\n",
    "reco_error = np.square(x_true-x_reco)\n",
    "z = z_test\n",
    "byz = nf.inverse(z)\n",
    "detJ = nf.inverse_log_det_jacobian(z)\n",
    "apae = -0.5*np.dot(reco_error,sigma**(-1)) - \\\n",
    "        0.5*np.linalg.norm(byz,axis=1)**2 + detJ\n",
    "\n",
    "byz = cnf.inverse([z, c_test])\n",
    "detJ = cnf.inverse_log_det_jacobian([z, c_test])\n",
    "cpae = -0.5*np.dot(reco_error,sigma**(-1)) - \\\n",
    "        0.5*np.linalg.norm(byz,axis=1)**2 + detJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pz_train-pz_train.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz0 =np.exp(pz)/np.exp(pz).max()\n",
    "cpz0 = np.exp(cpz)/np.exp(cpz).max()\n",
    "pz_train0 =(pz_train-pz_train.min())/(pz_train-pz_train.min()).max()\n",
    "cpz_train0 = (cpz_train-cpz_train.min())/(cpz_train-cpz_train.min()).max()\n",
    "synergy = np.sqrt(pz0*(nmse/nmse.max()))\n",
    "synergy_train = np.sqrt(pz_train0*(nmse_train/nmse_train.max()))\n",
    "csynergy = np.sqrt(cpz0*(nmse/nmse.max()))\n",
    "csynergy_train = np.sqrt(cpz_train0*(nmse_train/nmse_train.max()))\n",
    "\n",
    "scores_train = {\n",
    "    'pz': -pz_train,\n",
    "    'cpz': -cpz_train,\n",
    "    'mse': mse_train,\n",
    "    'nmse': nmse_train,\n",
    "    'pae': -apae_train,\n",
    "    'cpae': -cpae_train,\n",
    "    'pzr': -pzr_train,\n",
    "    'cpzr': -cpzr_train,\n",
    "    'synergy': -synergy_train,\n",
    "    'csynergy': -csynergy_train\n",
    "    }\n",
    "\n",
    "scores_test = {\n",
    "    'pz': -pz,\n",
    "    'cpz': -cpz,\n",
    "    'mse': mse,\n",
    "    'nmse': nmse,\n",
    "    'pae': -apae,\n",
    "    'cpae': -cpae,\n",
    "    'pzr': -pzr,\n",
    "    'cpzr': -cpzr,\n",
    "    'synergy': -synergy,\n",
    "    'csynergy': -csynergy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def get_JSdiv(scores, mjj):\n",
    "    prcs = np.arange(1,99)\n",
    "    jsdivs = {'prc': prcs}\n",
    "    n_full, b = np.histogram(mjj, bins=60, density=True)\n",
    "    for key, score in scores.items():\n",
    "        jsdivs[key] = []\n",
    "        for prc in prcs:\n",
    "            x_prc = np.percentile(score, prc)\n",
    "            i_prc = np.where(score >= x_prc)[0]\n",
    "            n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "            jsdivs[key].append(jensenshannon(n_full,n_prc))\n",
    "    return jsdivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsdivs = get_JSdiv(scores_train, dataset['mjj_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"presentation\"\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# mjj = dataset['mjj_train']\n",
    "# max_prc = 99\n",
    "# score = ascore_train\n",
    "# n_full, b = np.histogram(mjj, bins=60, density=True)\n",
    "# js_div = {}\n",
    "# for prc in range(1, max_prc+1):\n",
    "#     x_prc = np.percentile(ascore_train, prc)\n",
    "#     i_prc = np.where(ascore_train >= x_prc)[0]\n",
    "#     n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "#     js_div[prc] = jensenshannon(n_full,n_prc)\n",
    "\n",
    "# cjs_div = {}\n",
    "# for prc in range(1, max_prc+1):\n",
    "#     x_prc = np.percentile(cascore_train, prc)\n",
    "#     i_prc = np.where(cascore_train >= x_prc)[0]\n",
    "#     n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "#     cjs_div[prc] = jensenshannon(n_full,n_prc)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key in jsdivs.keys():\n",
    "    if key is not 'prc':\n",
    "        fig.add_trace(\n",
    "    go.Scatter(x=jsdivs['prc'].tolist(), y=jsdivs[key], mode='lines',\n",
    "        name=key)\n",
    "    )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=list(js_div.keys()), y=list(js_div.values()), mode='lines',\n",
    "#         name=\"MAF\", line=dict(color=\"plum\", width=3))\n",
    "# )\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=list(cjs_div.keys()), y=list(cjs_div.values()), mode='lines',\n",
    "#         name=\"CondMAF\", line=dict(color=\"tomato\", width=3))\n",
    "# )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Mass sculpting\",\n",
    "    xaxis_title = \"Percentile Cut\",\n",
    "    yaxis_title = \"Jensenâ€“Shannon\",\n",
    "    margin={'l': 80, 'b': 40, 't': 40, 'r': 0},\n",
    "    width=750, height=450\n",
    "\n",
    ")\n",
    "fig.show('svg')\n",
    "fig.write_image(\"cond-JS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.express as px\n",
    "\n",
    "def binarize(label):\n",
    "    return 1 if label == 'sig' else 0\n",
    "labels = np.array(list(map(binarize, dataset['labels'])))\n",
    "\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(labels, ascore)\n",
    "# nf_auc = auc(1-fpr, tpr)\n",
    "\n",
    "# cfpr, ctpr, thresholds = roc_curve(labels, cascore)\n",
    "# cnf_auc = auc(1-cfpr, ctpr)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for key,score in scores_test.items():\n",
    "    print(key)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, score)\n",
    "    vauc = auc(1-fpr, tpr)    \n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=tpr, y=1-fpr, mode='lines',\n",
    "        name=f\"{key} (AUC:{vauc:.2f})\",)\n",
    "        )\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=tpr, y=1-fpr, mode='lines',\n",
    "#         name=f\"NF (AUC:{nf_auc:.2f})\", line=dict(color=\"Plum\", width=2))\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter(x=ctpr, y=1-cfpr, mode='lines',\n",
    "#         name=f\"cNF (AUC:{cnf_auc:.2f})\", line=dict(color=\"Tomato\", width=2))\n",
    "# )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800, height=500,\n",
    "    xaxis_title = \"Signal efficiency\",\n",
    "    yaxis_title = \"Background Rejection\",\n",
    "    margin={'l': 60, 'b': 60, 't': 40, 'r': 0},\n",
    "    showlegend = True\n",
    ")\n",
    "\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.write_image(\"cflows.png\")\n",
    "fig.show('svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.exp(pz)/np.exp(pz).max()).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_fractions = {\n",
    "#     'bkg':200_000,\n",
    "#     'sig':400\n",
    "# }\n",
    "# test2 = loader.make_test(test_fractions, replace=False)\n",
    "\n",
    "\n",
    "# z_test2 = ae.encode(test2['x_test'])\n",
    "# c_test2 = scaler.transform(test2['mjj_test'].reshape(-1,1))\n",
    "\n",
    "# cpz = cnf([z_test2, c_test2]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# pio.templates.default = \"presentation\"\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# prc=95\n",
    "\n",
    "# ascore = -cpz\n",
    "\n",
    "# x_min = np.percentile(ascore, 1)\n",
    "# x_max = np.percentile(ascore, 99)\n",
    "# x_prc = np.percentile(ascore, prc)\n",
    "# i_prc = (ascore >= x_prc)\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x=ascore, name='Test dataset', \n",
    "#                            marker_color='plum', nbinsx=400),\n",
    "#              )\n",
    "# fig.add_vline(x=x_prc, y1=5100, line_width=2, line_color='firebrick', \n",
    "#               annotation_text=f\"{prc}th percentile\", \n",
    "#               annotation_position=\"top right\",\n",
    "#               )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     xaxis_title='Anomaly Score',\n",
    "#     #title_text=r'Cut on Anomaly Score',\n",
    "#     width=600)\n",
    "# fig.show('svg')\n",
    "\n",
    "# ##################################################3\n",
    "# mjj=test2['mjj_test']\n",
    "# def binarize(label):\n",
    "#     return 1 if label == 'sig' else 0\n",
    "# labels = np.array(list(map(binarize, test2['labels'])))\n",
    "# sig_label = (labels==1)\n",
    "# bkg_label = (labels==0)\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x=mjj[bkg_label], name=\"Full test bkg\",\n",
    "#                           marker_color='steelblue'))\n",
    "# fig.add_trace(go.Histogram(x=mjj[sig_label], name=\"Full test sig\",\n",
    "#                           marker_color='darkorange'))\n",
    "# sb = 100*sum(sig_label)/sum(bkg_label)\n",
    "# fig.update_layout(\n",
    "#     xaxis_title='$$m_{jj}$$',\n",
    "#     title_text=f'Dijet mass spectrum of test dataset S/B={sb:.2f}%',\n",
    "#     width=600,\n",
    "#     barmode='stack'\n",
    "#     )\n",
    "# fig.show('svg')        \n",
    "# #################################################3     \n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x=mjj[i_prc&bkg_label], name=\"Full test bkg\",\n",
    "#                           marker_color='steelblue', nbinsx=100))\n",
    "# fig.add_trace(go.Histogram(x=mjj[i_prc&sig_label], name=\"Full test sig\",\n",
    "#                           marker_color='darkorange'))\n",
    "# sb = 100*sum(i_prc&sig_label)/sum(i_prc&bkg_label)\n",
    "# fig.update_layout(\n",
    "#     xaxis_title='$$m_{jj}$$',\n",
    "#     title_text=f'Dijet mass spectrum of test dataset after cut S/B={sb:.2f}%',\n",
    "#     width=600,\n",
    "#     barmode='stack'\n",
    "#     )\n",
    "# fig.show('svg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
