{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.loaders.LHCO import ScalarLoaderLHCO, DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ScalarLoaderLHCO.from_json(\"../pae/configs/loader/rnd_scalar_2j.json\")\n",
    "mjj = ScalarLoaderLHCO.from_json(\"../pae/configs/loader/rnd_scalar_mjj.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = DatasetBuilder(x, mjj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.data_preparation(sample_sizes ={'sig':1000, 'bkg': 1_000_000}, fit_key='bkg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = {'train':{'bkg':1_000_000}, 'test':{'sig':100, 'bkg': 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = builder.make_dataset(train = {'bkg':1_000_000}, test={'sig':100, 'bkg': 10_000}, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.density import GMM, ConvKDE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fftkde = ConvKDE()\n",
    "fftkde.fit(dataset[\"mjj_train\"])#, range=(1000, 9500)) \n",
    "y_kde = fftkde.evaluate(dataset[\"mjj_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ref = np.linspace(1600, 8000, 1701)\n",
    "\n",
    "y_kde = fftkde.evaluate(x_ref)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "init_notebook_mode(connected = True)\n",
    "pio.templates.default = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 18:01:37.675307: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-21 18:01:39.085851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30997 MB memory:  -> device: 0, name: NVIDIA Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2021-10-21 18:01:39.087514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30997 MB memory:  -> device: 1, name: NVIDIA Tesla V100S-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from pae.models.autoencoder import DenseAutoencoder\n",
    "from pae.models.flows import MAF\n",
    "from pae.models.nn import PaeBuilder\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "\n",
    "ae_config = {\n",
    "    'input_dim':47, \n",
    "    'encoding_dim':10, \n",
    "    'units':[30, 20, 15],\n",
    "    'weight_reg':tfk.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    'output_activation':tf.nn.sigmoid\n",
    "}\n",
    "nf_config = {\n",
    "    'n_dims':10, \n",
    "    'n_layers':5, \n",
    "    'units':[32 for _ in range(4)]\n",
    "}\n",
    "optimizer_ae = {\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "optimizer_nf = {\n",
    "    'learning_rate': 0.005\n",
    "}\n",
    "\n",
    "builder = PaeBuilder()\n",
    "builder.make_ae_model(DenseAutoencoder, ae_config)\n",
    "builder.make_ae_optimizer(tfk.optimizers.Adam, optimizer_ae)\n",
    "builder.make_nf_model(MAF, nf_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_nf)\n",
    "builder.compile_ae()\n",
    "builder.compile_nf()\n",
    "pae = builder.pae\n",
    "pae.ae(np.zeros(47).reshape(1,-1))\n",
    "pae.nf(np.zeros(10).reshape(1,-1))\n",
    "pae.ae.load_weights(\"./logs/full-cpu-kde-20211020-165124/ae.h5\")\n",
    "pae.nf.load_weights(\"./logs/full-cpu-kde-20211020-165124/nf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875000,)\n",
      "(125000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fold5 = KFold(8, shuffle=True)\n",
    "q= fold5.split(dataset[\"x_train\"])\n",
    "x_train, x_valid = next(q)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor \n",
    "tfd = tfp.distributions\n",
    "pae.compute_implicit_sigma(dataset['x_train'][x_valid])\n",
    "from datetime import datetime\n",
    "STEPS = 500\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "sigma = tf.constant(tf.sqrt(pae.sigma_square))\n",
    "z_ = tf.Variable(pae.ae.encoder(dataset['x_test']))\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "map_summary_writer = tf.summary.create_file_writer(f\"./testing/{timestamp}/map\")\n",
    "print(z_.shape)\n",
    "\n",
    "@tf.function\n",
    "def max_apriori_prob(x, z, sigma, pae):\n",
    "    distrs = tfd.MultivariateNormalDiag(loc=x, scale_diag=sigma)\n",
    "    nf_ll = pae.nf(z)\n",
    "    reco = pae.ae.decoder(z)\n",
    "    gauss_ll = distrs.log_prob(reco)\n",
    "    #tf.print(\"gauss:\", gaussll, \"nf:\", nfll, \"\\n\")\n",
    "    return  tf.reduce_mean(-nf_ll - gauss_ll) \n",
    "\n",
    "\n",
    "@tf.function\n",
    "def find_map(x_):\n",
    "    global z_\n",
    "    if z_ is None:\n",
    "        z_ = tf.Variable(pae.ae.encoder(x_))\n",
    "    z_.assign(pae.ae.encoder(x_))\n",
    "    for i in range(STEPS):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z_)\n",
    "            nll = max_apriori_prob(x_, z_, sigma, pae)\n",
    "        grad = tape.gradient(nll, [z_])\n",
    "        opt.apply_gradients(zip(grad, [z_]))\n",
    "        with map_summary_writer.as_default():\n",
    "            tf.summary.scalar('nll', nll, step=i)\n",
    "    return z_\n",
    "\n",
    "@tf.function\n",
    "def tf_graph_map(*args, parallel_iterations=1000):\n",
    "    return tf.map_fn(*args, parallel_iterations=parallel_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.convert_to_tensor(dataset['x_test'], dtype=tf.float32)\n",
    "\n",
    "#ds.shape\n",
    "# ds = tf.data.Dataset.from_tensor_slices(dataset['x_test'].astype(np.float32))\n",
    "# ds = ds.cache()\n",
    "#ds = ds.batch(BATCH_SIZE)\n",
    "#ds = ds.prefetch()\n",
    "#print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 18:12:13.295761: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-10-21 18:12:13.295940: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-10-21 18:19:46.839539: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-10-21 18:19:46.918427: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2021-10-21 18:19:51.402454: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 62017 callback api events and 62016 activity events. \n",
      "2021-10-21 18:19:58.678041: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-10-21 18:20:07.941078: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58\n",
      "\n",
      "2021-10-21 18:20:13.999695: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.trace.json.gz\n",
      "2021-10-21 18:20:24.661249: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58\n",
      "\n",
      "2021-10-21 18:20:24.676372: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.memory_profile.json.gz\n",
      "2021-10-21 18:20:25.302852: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58\n",
      "Dumped tool data for xplane.pb to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./testing/20211021-181206/plugins/profile/2021_10_21_18_19_58/baaf09.nipne.ro.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 49s, sys: 55.9 s, total: 11min 45s\n",
      "Wall time: 8min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.profiler.experimental.start(f\"./testing/{timestamp}\")\n",
    "with tf.device(\"GPU:0\"):\n",
    "    # ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    # for i, x in enumerate(ds):\n",
    "    #     ta.write(i, find_map(x))\n",
    "    # z_map = ta.concat()\n",
    "    # ta.close()\n",
    "    z_map = find_map(ds)\n",
    "tf.profiler.experimental.stop()\n",
    "#     z_map = tf_graph_map(find_map, x_test, parallel_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(z_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.51437443 0.71470994 0.39675683 0.12056316 0.5238756  0.2279173\n",
      " 0.8093918  0.7783619  0.05651172 0.8553338 ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(z_map[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70f45a738872f66498ef9def3ce24bedd18274b41618f938c7df5c328e4074a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
