{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pae.analysis.scalar_v2 import HLFAnalysis\n",
    "from pae.models.nn import PaeBuilder\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "np.random.seed(SEED) \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 02:57:32.703347: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-16 02:57:34.102365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30989 MB memory:  -> device: 0, name: NVIDIA Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-05-16 02:57:34.104050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30989 MB memory:  -> device: 1, name: NVIDIA Tesla V100S-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.utils import load_json, dump_json\n",
    "\n",
    "from pae.loaders.LHCO import ScalarLoaderLHCO, DatasetBuilder\n",
    "\n",
    "x = ScalarLoaderLHCO.from_json(\"../pae/configs/loader/bbox1_scalar_2j.json\")\n",
    "mjj = ScalarLoaderLHCO.from_json(\"../pae/configs/loader/bbox1_scalar_mjj.json\")\n",
    "builder = DatasetBuilder(x, mjj)\n",
    "builder.data_preparation(sample_sizes ={'box_s':834, 'box_b': 999166, 'bkg': 500_000}, fit_key='bkg')\n",
    "# dataset = builder.make_dataset(train = {'box_s':834, 'box_b': 999166}, test={'box_s':834, 'box_b': 999166}, replace=True)\n",
    "dataset = builder.make_dataset(train = {'box_s':100, 'box_b': 1900}, test={'box_s':100, 'box_b': 1900}, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk\n",
    "import tensorflow as tf\n",
    "\n",
    "from pae.models.autoencoder import DenseAutoencoder\n",
    "from pae.models.flows import CondMAF, MAF\n",
    "from pae.models.nn import PaeBuilder\n",
    "from pae.analysis.scalar_v2 import HLFAnalysis\n",
    "\n",
    "task = HLFAnalysis(\"../stuff.json\", dataset.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 02:58:00.095173: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "WARNING:tensorflow:From /home/idinu/.conda/envs/tf-gpu/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 7.99999907030724e-06.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-06.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.1999995826481613e-07.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.9999996079131965e-05.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 7.99999907030724e-06.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-06.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.1999995826481613e-07.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n"
     ]
    }
   ],
   "source": [
    "task.cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mjj_train', 'mjj_test', 'x_train', 'x_test', 'labels_train', 'labels_test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.03203203 0.48898899 ... 0.99647507 0.8385234  0.46896897]\n",
      " [0.         0.08658659 0.31331331 ... 0.99487758 0.69713664 0.27277277]\n",
      " [0.         0.26376376 0.71271271 ... 0.99442647 0.72039235 0.74574575]\n",
      " ...\n",
      " [0.         0.36836837 0.83083083 ... 0.71862961 0.60610817 0.78878879]\n",
      " [0.         0.26376376 0.56906907 ... 0.2747823  0.27068633 0.60910911]\n",
      " [0.         0.47497497 0.71271271 ... 0.97008277 0.71366363 0.71821822]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"x_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "70f45a738872f66498ef9def3ce24bedd18274b41618f938c7df5c328e4074a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
