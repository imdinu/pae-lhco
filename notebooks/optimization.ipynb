{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tf-gpu",
   "display_name": "tf-gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from loaders.LHCO import LhcoRnDLoader\n",
    "from analysis.scalar import HLFAnalysis\n",
    "from models.nn import PaeBuilder\n",
    "from utils import load_json, dump_json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../configs/analysis/trial.json']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "configs_folder = '../configs/analysis'\n",
    "config_files = glob.glob(configs_folder+'/*.json')\n",
    "config_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'trial'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "config_files[0].replace('.', '/').split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "plots_dir = './figures/'\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.mkdir(plots_dir)\n",
    "results_history = {\n",
    " 'id': [],\n",
    " 'config': [],\n",
    " 'js_div_train': [],\n",
    " 'js_div_test': [],\n",
    " 'sig_eff': [],\n",
    " 'bkg_rej': [],\n",
    " 'auc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Epoch 1/60\n",
      "800/800 [==============================] - 6s 6ms/step - loss: 627.8270 - val_loss: 308863.5625\n",
      "Epoch 2/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 472.6789 - val_loss: 306993.5000\n",
      "Epoch 3/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 439.6953 - val_loss: 279228.9688\n",
      "Epoch 4/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 446.1837 - val_loss: 241646.3594\n",
      "Epoch 5/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 438.9169 - val_loss: 239815.4219\n",
      "Epoch 6/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 385.4571 - val_loss: 219290.9844\n",
      "Epoch 7/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 379.0493 - val_loss: 219682.4375\n",
      "Epoch 8/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 367.0194 - val_loss: 218906.7500\n",
      "Epoch 9/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 353.7977 - val_loss: 213985.8750\n",
      "Epoch 10/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 383.6612 - val_loss: 183938.2969\n",
      "Epoch 11/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 373.9258 - val_loss: 196876.9688\n",
      "Epoch 12/60\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 382.4551 - val_loss: 171274.0000\n",
      "Epoch 13/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 343.5497 - val_loss: 192302.1094\n",
      "Epoch 14/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 345.1549 - val_loss: 178923.9375\n",
      "Epoch 15/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 371.6269 - val_loss: 184964.2812\n",
      "Epoch 16/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 336.1721 - val_loss: 166468.6250\n",
      "Epoch 17/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 333.3018 - val_loss: 183226.8125\n",
      "Epoch 18/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 326.5794 - val_loss: 171530.2188\n",
      "Epoch 19/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 343.1152 - val_loss: 170851.0625\n",
      "Epoch 20/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 321.7173 - val_loss: 183202.7969\n",
      "Epoch 21/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 325.7200 - val_loss: 173442.2344\n",
      "Epoch 22/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 319.8999 - val_loss: 166270.0000\n",
      "Epoch 23/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 294.4654 - val_loss: 165074.9531\n",
      "Epoch 24/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 325.5687 - val_loss: 168341.6250\n",
      "Epoch 25/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 284.9736 - val_loss: 176540.1094\n",
      "Epoch 26/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 290.1595 - val_loss: 196934.4062\n",
      "Epoch 27/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 318.4392 - val_loss: 244623.2500\n",
      "Epoch 28/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 307.1628 - val_loss: 163271.8281\n",
      "Epoch 29/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 284.3729 - val_loss: 162402.2188\n",
      "Epoch 30/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 280.1127 - val_loss: 167995.4688\n",
      "Epoch 31/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 293.4995 - val_loss: 170222.2500\n",
      "Epoch 32/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 287.4113 - val_loss: 159236.5625\n",
      "Epoch 33/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 287.4990 - val_loss: 180538.2812\n",
      "Epoch 34/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 277.8274 - val_loss: 179187.2969\n",
      "Epoch 35/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 291.0133 - val_loss: 177631.4375\n",
      "Epoch 36/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 293.3613 - val_loss: 172497.1719\n",
      "Epoch 37/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 296.0394 - val_loss: 162652.4531\n",
      "Epoch 38/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 291.0150 - val_loss: 179343.0625\n",
      "Epoch 39/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 293.6200 - val_loss: 166717.0000\n",
      "Epoch 40/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 301.2505 - val_loss: 169549.8438\n",
      "Epoch 41/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 286.1839 - val_loss: 174332.2812\n",
      "Epoch 42/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 275.0791 - val_loss: 162104.4844\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 43/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 253.7585 - val_loss: 168579.5000\n",
      "Epoch 44/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 272.1215 - val_loss: 169758.2812\n",
      "Epoch 45/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 269.0899 - val_loss: 162236.4062\n",
      "Epoch 46/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 282.6375 - val_loss: 159821.1719\n",
      "Epoch 47/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 264.8952 - val_loss: 160011.2969\n",
      "Epoch 48/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 263.1402 - val_loss: 157993.9375\n",
      "Epoch 49/60\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 257.1687 - val_loss: 157455.8906\n",
      "Epoch 50/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 258.0483 - val_loss: 153191.2812\n",
      "Epoch 51/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 247.5997 - val_loss: 153086.1406\n",
      "Epoch 52/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 270.6869 - val_loss: 156196.0000\n",
      "Epoch 53/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 256.8910 - val_loss: 161270.8125\n",
      "Epoch 54/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 258.1664 - val_loss: 156998.2188\n",
      "Epoch 55/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 262.3987 - val_loss: 158172.1406\n",
      "Epoch 56/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 256.0180 - val_loss: 154495.2188\n",
      "Epoch 57/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 249.4570 - val_loss: 157501.4844\n",
      "Epoch 58/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 240.2149 - val_loss: 160850.2031\n",
      "Epoch 59/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 251.0196 - val_loss: 155062.2344\n",
      "Epoch 60/60\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.8942 - val_loss: 154363.2500\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 8s 6ms/step - loss: -9.2307 - val_loss: -12.7769\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -14.0676 - val_loss: -15.1191\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -15.1704 - val_loss: -15.6941\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -15.6631 - val_loss: -15.4850\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.0451 - val_loss: -16.2709\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.2893 - val_loss: -16.7454\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.2568 - val_loss: -16.9728\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -16.6447 - val_loss: -16.6753\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -16.6672 - val_loss: -17.1947\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.8595 - val_loss: -16.2936\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.9516 - val_loss: -15.0671\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.6557 - val_loss: -16.7832\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -17.0079 - val_loss: -17.5174\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.9822 - val_loss: -16.9887\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -17.1131 - val_loss: -17.2556\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -17.1738 - val_loss: -17.0349\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -16.8925 - val_loss: -17.2550\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -17.3453 - val_loss: -16.5194\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -17.9999 - val_loss: -18.1083\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.1657 - val_loss: -18.1653\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.2016 - val_loss: -18.1822\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.2314 - val_loss: -18.2678\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.2319 - val_loss: -18.3261\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.2590 - val_loss: -18.3164\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.2790 - val_loss: -18.3623\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.2968 - val_loss: -18.3277\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.3234 - val_loss: -18.3698\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.3469 - val_loss: -18.3493\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.3257 - val_loss: -18.4279\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 5s 7ms/step - loss: -18.3819 - val_loss: -18.4056\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.3844 - val_loss: -18.3793\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.3925 - val_loss: -18.5023\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.4212 - val_loss: -18.4689\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.4145 - val_loss: -18.4864\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.4308 - val_loss: -18.4388\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.4397 - val_loss: -18.3922\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.4704 - val_loss: -18.4351\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001999999862164259.\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6561 - val_loss: -18.6546\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6578 - val_loss: -18.6338\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.6713 - val_loss: -18.6516\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.6508 - val_loss: -18.6858\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.6746 - val_loss: -18.6467\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6793 - val_loss: -18.6820\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.6779 - val_loss: -18.6600\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6842 - val_loss: -18.6141\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6842 - val_loss: -18.6879\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 4s 5ms/step - loss: -18.6968 - val_loss: -18.6505\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 4s 6ms/step - loss: -18.7107 - val_loss: -18.6754\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.6876 - val_loss: -18.6550\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 6ms/step - loss: -18.7113 - val_loss: -18.6972\n"
     ]
    }
   ],
   "source": [
    " for file in config_files:\n",
    "    analysis_cfg = load_json(file)\n",
    "    analysis_cfg\n",
    "\n",
    "    config = analysis_cfg.copy()\n",
    "\n",
    "    loader_json = analysis_cfg.pop('ANA:loader')\n",
    "    dataset_json = analysis_cfg.pop('ANA:dataset')\n",
    "    density_estimator = analysis_cfg.pop('ANA:estimator')\n",
    "    prc = analysis_cfg.pop('ANA:percentile')\n",
    "\n",
    "    loader = LhcoRnDLoader.from_json(loader_json)\n",
    "    dataset_cfg = load_json(dataset_json)\n",
    "    dataset = loader.make_full_dataset(**dataset_cfg)\n",
    "\n",
    "    builder = PaeBuilder()\n",
    "\n",
    "    pae, ae_train, nf_train = builder.from_json(analysis_cfg)\n",
    "    task = HLFAnalysis(pae, dataset=dataset)\n",
    "    task.reweighting(estimator=density_estimator, fit_key='mjj_train')\n",
    "    if 'cond' in config['nf_model']:\n",
    "        task.make_cond_inputs(['mjj_train', 'mjj_test', 'mjj_valid'])\n",
    "    task.train(ae_train,nf_train)\n",
    "    result = task.evaluate(prc = prc)\n",
    "    for key in result.keys():\n",
    "        results_history[key].append(result[key])\n",
    "    \n",
    "    id = config_files[0].replace('.', '/').split('/')[-2]\n",
    "    results_history['id'].append(id)\n",
    "    results_history['config'].append(config)\n",
    "    task.plot_training(plots_dir+id+'_train.png')\n",
    "    task.plot_latent_space(plots_dir+id+'_latent.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': ['trial'],\n",
       " 'config': [{'ANA:loader': '../configs/loader/default_rnd.json',\n",
       "   'ANA:dataset': '../configs/loader/default_dataset.json',\n",
       "   'ANA:estimator': 'gmm',\n",
       "   'ANA:percentile': 95,\n",
       "   'ae_model': 'dense_ae',\n",
       "   'nf_model': 'cond_maf',\n",
       "   'AE:input_dim': 47,\n",
       "   'AE:encoding_dim': 10,\n",
       "   'AE:units': [30, 20, 15],\n",
       "   'AE:hidden_activation': 'relu',\n",
       "   'AE:output_activation': 'sigmoid',\n",
       "   'AE:weight_reg': {'l1': 1e-06},\n",
       "   'AE:bias_reg': {},\n",
       "   'AE:output_reg': {},\n",
       "   'NF:n_dims': 10,\n",
       "   'NF:n_layers': 5,\n",
       "   'NF:units': [32, 32, 32, 32],\n",
       "   'ae_optimizer': 'adam',\n",
       "   'nf_optimizer': 'adam',\n",
       "   'ae_optimizer_kwargs': {'lr': 0.001},\n",
       "   'nf_optimizer_kwargs': {'lr': 0.005},\n",
       "   'ae_callbacks': ['reduce_lr_on_plateau'],\n",
       "   'ae_callbacks_kwargs': [{'factor': 0.2, 'patience': 10, 'verbose': 1}],\n",
       "   'nf_callbacks': ['reduce_lr_on_plateau'],\n",
       "   'nf_callbacks_kwargs': [{'factor': 0.2, 'patience': 5, 'verbose': 1}],\n",
       "   'ae_epochs': 60,\n",
       "   'ae_batch_size': 200,\n",
       "   'nf_epochs': 50,\n",
       "   'nf_batch_size': 200}],\n",
       " 'js_div_train': [0.033545038946786995],\n",
       " 'js_div_test': [0.08283154366165268],\n",
       " 'sig_eff': [0.06856],\n",
       " 'bkg_rej': [0.96856],\n",
       " 'auc': [0.7118238844999999]}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "results_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}