{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Autoencode on LHCO data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import machine lerning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pae.models.autoencoder import DenseAutoencoder\n",
    "from pae.models.flows import MAF\n",
    "from pae.models.nn import PaeBuilder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(\"tensorflow\", tf.__version__)\n",
    "print(\"tensorflow-probability\", tfp.__version__)\n",
    "print(\"Available devices:\", *[dev[1] for dev in devices])\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED) \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "init_notebook_mode(connected = True)\n",
    "pio.templates.default = \"plotly_dark\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.utils import load_json, dump_json\n",
    "\n",
    "from pae.loaders.LHCO import ScalarLoaderLHCO, ImageLoaderLHCO, DatasetBuilder\n",
    "\n",
    "x = ImageLoaderLHCO.from_json(\"pae/configs/loader/images_rnd.json\")\n",
    "mjj = ScalarLoaderLHCO.from_json(\"pae/configs/loader/scalar_mjj.json\")\n",
    "builder = DatasetBuilder(x, mjj)\n",
    "builder.data_preparation(sample_sizes ={'sig':15_000, 'bkg': 110_000}, fit_key='bkg')\n",
    "dataset = builder.make_dataset(train = {'bkg':100_000}, test={'sig':10_000, 'bkg': 10_000}, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import LogNorm\n",
    "\n",
    "# vmin = np.min([dataset[key].min() for key in ['x_train', 'x_test', 'x_valid']])\n",
    "# vmax = np.max([dataset[key].max() for key in ['x_train', 'x_test', 'x_valid']])\n",
    "# eps = 1e-6\n",
    "# print(vmin, vmax)\n",
    "# ln = LogNorm(vmin=eps, vmax=vmax)\n",
    "\n",
    "# for key in ['x_train', 'x_test', 'x_valid']:\n",
    "#     dataset[key] = ln(dataset[key][:,:,:,:2])+1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min([dataset[key].min() for key in ['x_train', 'x_valid']])\n",
    "vmax = np.max([dataset[key].max() for key in ['x_train', 'x_valid']])\n",
    "eps = 1e-6\n",
    "print(vmin, vmax)\n",
    "\n",
    "def rescale(x):\n",
    "    return x\n",
    "\n",
    "for key in ['x_train', 'x_test', 'x_valid']:\n",
    "    dataset[key] = rescale(dataset[key][:,:,:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['x_test'].shape\n",
    "dataset['x_train'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from pae.models.autoencoder import Autoencoder\n",
    "from tensorflow.keras.regularizers import L1, L2, L1L2\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class CNNAE(Autoencoder):\n",
    "    def __init__(self, enc, dec, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = enc\n",
    "        self.decoder = dec\n",
    "        self.layers\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Run the inputs through the full autoencoder\"\"\"\n",
    "        encoding = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(encoding)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encode(self, inputs):\n",
    "        \"\"\"Genereate the latent representation of the inputs\"\"\"\n",
    "        return self.encoder.predict(inputs)\n",
    "\n",
    "    def decode(self, encoding):\n",
    "        \"\"\"Reconstruct the inputs using a given latent representation\"\"\"\n",
    "        return self.decoder.predict(encoding)\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "latent_dim = 25\n",
    "n_channels = 2\n",
    "\n",
    "l1 = 0\n",
    "l2 = 0\n",
    "\n",
    "enc = Sequential([\n",
    "  layers.InputLayer(input_shape=(img_height, img_width, n_channels)),\n",
    "  layers.Conv2D(32, 3, strides=1, padding='same', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "  layers.MaxPool2D(2),\n",
    "  layers.Conv2D(64, 3, strides=1, padding='valid', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "  layers.MaxPool2D(2),\n",
    "  layers.Conv2D(1, 3, strides=1, padding='same', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(latent_dim, activation='tanh')\n",
    "])\n",
    "\n",
    "dec = Sequential([\n",
    "  layers.InputLayer(input_shape=enc.layers[-1].output_shape[1:]),\n",
    "  layers.Dense(49),\n",
    "  layers.Reshape(target_shape=(7,7,1)),\n",
    "  layers.UpSampling2D(2),\n",
    "  layers.Conv2DTranspose(64, 3, strides=1, padding='valid', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "  layers.UpSampling2D(2),\n",
    "  layers.Conv2DTranspose(32, 3, strides=1, padding='same', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "  layers.Conv2DTranspose(n_channels, 3, strides=1, padding='same', activation='relu', kernel_regularizer=L1L2(l1,l2)),\n",
    "])\n",
    "\n",
    "enc.summary()\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "builder = PaeBuilder()\n",
    "\n",
    "ae = CNNAE(enc,dec)\n",
    "\n",
    "nf_config = {\n",
    "    'n_dims':25, \n",
    "    'n_layers':6, \n",
    "    'units':[32 for i in range(4)]\n",
    "}\n",
    "optimizer_ae = {\n",
    "    'lr': 0.001\n",
    "}\n",
    "optimizer_nf = {\n",
    "    'lr': 0.005\n",
    "}\n",
    "\n",
    "builder._ae = ae\n",
    "builder.make_ae_optimizer(tfk.optimizers.Adam, optimizer_ae)\n",
    "builder.make_nf_model(MAF, nf_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_nf)\n",
    "builder.compile_ae(loss='mean_squared_logarithmic_error')\n",
    "builder.compile_nf()\n",
    "pae = builder.pae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#w_kde_valid = fftkde.get_weights(dataset[\"mjj_valid\"])\n",
    "#w_gmm_valid = gmm.get_weights(dataset[\"mjj_valid\"])\n",
    "\n",
    "ae_train ={\n",
    "    'batch_size':32,\n",
    "    'epochs':40,\n",
    "    #'sample_weight':w_kde,\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"]),#,w_kde_valid),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "\n",
    "nf_train ={\n",
    "    'batch_size':100,\n",
    "    'epochs':50,\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"]),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    %time pae.fit(dataset[\"x_train\"],None,ae_train,nf_train)\n",
    "\n",
    "#%time pae.ae.fit(x=dataset[\"x_train\"], y=dataset[\"x_train\"], **ae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.plotting import loss_plot\n",
    "\n",
    "fig = loss_plot(pae.history)\n",
    "fig.show('vscode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device(\"/device:CPU:0\"):\n",
    "z_true = pae.ae.encode(dataset['x_train'])\n",
    "z_sample = pae.nf.sample(dataset['x_train'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pae.plotting import latent_space_plot\n",
    "#pio.templates.default = \"plotly\"\n",
    "fig = latent_space_plot(z_true, z_sample)\n",
    "fig.show('vscode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "#img = pae.ae.decode(z_true[:100])\n",
    "img = pae.ae.predict(dataset['x_train'][:100,:,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no=17\n",
    "ch = 0\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(13,5))\n",
    "for data, ax in zip([dataset['x_train'][no][:,:,ch], img[no][:,:,ch]], axes.flat):\n",
    "    im = ax.imshow(data, norm=LogNorm())\n",
    "\n",
    "fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.title('Background')\n",
    "# im = plt.imshow(dataset['x_train'][no][:,:,ch])\n",
    "# fig.colorbar(im)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.title('Reconstruction')\n",
    "# plt.imshow(img[no][:,:,ch])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reco_error(x):\n",
    "    return np.square(np.log(pae.ae.predict(x)+1)-np.log(x+1))\n",
    "\n",
    "def anomaly_score(x):\n",
    "    \"\"\"Calculates the anomaly scores for the input data\"\"\"\n",
    "    sigma = np.mean(reco_error(dataset['x_valid']), axis=0)**(-1)\n",
    "    mse = np.square(pae.ae.predict(x)-x)\n",
    "    z = pae.ae.encode(x)\n",
    "    byz = pae.nf.inverse(z)\n",
    "    detJ = pae.nf.inverse_log_det_jacobian(z)\n",
    "    ascore = -0.5*np.mean(mse*sigma, axis=(1,2,3)) - \\\n",
    "            0.5*np.linalg.norm(byz,axis=1)**2 + detJ\n",
    "    return ascore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.mean(reco_error(dataset['x_valid']), axis=0)**(-1)\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.title('Sigma')\n",
    "im = plt.imshow(sigma[:,:,0], norm=LogNorm())\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "    sigma = np.mean(reco_error(dataset['x_valid']), axis = 0)**(-1)\n",
    "    mse_test = reco_error(dataset['x_test'])\n",
    "    test_mse = np.mean(mse_test*sigma, axis=(1,2,3))\n",
    "\n",
    "    mse_train = reco_error(dataset['x_train'])\n",
    "    train_mse = np.mean(mse_train*sigma, axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "    test_ascore = -anomaly_score(dataset['x_test'])\n",
    "    train_ascore = -anomaly_score(dataset['x_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(13,5))\n",
    "axes[0].set_title('Background')\n",
    "axes[0].imshow(np.mean(mse_test[10_000:,:,:]*sigma, axis=0)[:,:,0], norm=LogNorm())\n",
    "axes[1].set_title('Signal')\n",
    "axes[1].imshow(np.mean(mse_test[:10_000,:,:]*sigma, axis=0)[:,:,0], norm=LogNorm())\n",
    "fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(13,5))\n",
    "axes[0].set_title('Background')\n",
    "axes[0].imshow(np.mean(mse_test[10_000:,:,:], axis=0)[:,:,0], norm=LogNorm())\n",
    "axes[1].set_title('Signal')\n",
    "axes[1].imshow(np.mean(mse_test[:10_000,:,:], axis=0)[:,:,0], norm=LogNorm())\n",
    "fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(13,5))\n",
    "axes[0].set_title('Relative')\n",
    "axes[0].imshow(np.mean(mse_train*sigma, axis=0)[:,:,0], norm=LogNorm())\n",
    "axes[1].set_title('Absolute')\n",
    "axes[1].imshow(np.mean(mse_train, axis=0)[:,:,0], norm=LogNorm())\n",
    "fig.colorbar(im, ax=axes.ravel().tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lno = 2\n",
    "fno = 2\n",
    "cno = 0\n",
    "\n",
    "filters, biases = pae.ae.encoder.layers[lno].get_weights()\n",
    "print(filters.shape, biases.shape)\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "plt.figure(figsize=(12,8))\n",
    "for fno in range(filters.shape[-1]):\n",
    "    plt.subplot(5, filters.shape[-1]//4, fno+1)\n",
    "    f = filters[:, :, :, fno]\n",
    "    plt.imshow(f[:, :, cno])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc=95\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=test_ascore[10_000:], name='Background', \n",
    "                           marker_color='steelblue', nbinsx=80),\n",
    "             )\n",
    "fig.add_trace(go.Histogram(x=test_ascore[:10_000], name='Signal', \n",
    "                           marker_color='darkorange', nbinsx=80),\n",
    "             )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Anomaly Score',\n",
    "    title_text=r'Anomlay Score Distributions',\n",
    "    barmode='stack',\n",
    "    width=600)\n",
    "fig.show('vscode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "pio.templates.default = \"presentation\"\n",
    "mjj = dataset['mjj_train']\n",
    "max_prc = 99\n",
    "score = train_ascore\n",
    "n_full, b = np.histogram(mjj, bins=60, density=True)\n",
    "js_div = {}\n",
    "\n",
    "for prc in range(1, max_prc+1):\n",
    "    x_prc = np.percentile(score, prc)\n",
    "    i_prc = np.where(score >= x_prc)[0]\n",
    "    n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "    js_div[prc] = jensenshannon(n_full,n_prc)\n",
    "\n",
    "score = train_mse\n",
    "js_div_mse = {}\n",
    "for prc in range(1, max_prc+1):\n",
    "    x_prc = np.percentile(score, prc)\n",
    "    i_prc = np.where(score >= x_prc)[0]\n",
    "    n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "    js_div_mse[prc] = jensenshannon(n_full,n_prc)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(js_div.keys()), y=list(js_div.values()), mode='lines',\n",
    "        name=\"PAE ascore\", line=dict(color=\"plum\", width=3))\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(js_div_mse.keys()), y=list(js_div_mse.values()), mode='lines',\n",
    "        name=\"NMSE\", line=dict(color=\"steelblue\", width=3))\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text = \"Mass sculpting\",\n",
    "    xaxis_title = \"Percentile Cut\",\n",
    "    yaxis_title = \"Jensen–Shannon\",\n",
    "    margin={'l': 80, 'b': 40, 't': 40, 'r': 0},\n",
    "    width=750, height=450\n",
    "\n",
    ")\n",
    "fig.show('vscode')\n",
    "#fig.write_image(\"JS-plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.express as px\n",
    "\n",
    "def binarize(label):\n",
    "    return 1 if label == 'sig' else 0\n",
    "labels = np.array(list(map(binarize, dataset['labels_test'])))\n",
    "#labels = np.concatenate([np.ones(10_000),np.zeros(10_000)])\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels, test_ascore)\n",
    "pae_auc = auc(1-fpr, tpr)\n",
    "\n",
    "fpr_mse, tpr_mse, _ = roc_curve(labels, test_mse)\n",
    "nmse_auc = auc(1-fpr_mse, tpr_mse)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=tpr, y=1-fpr, mode='lines',\n",
    "        name=f\"PAE (AUC:{pae_auc:.2f})\", line=dict(color=\"Plum\", width=2))\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=tpr_mse, y=1-fpr_mse, mode='lines',\n",
    "        name=f\"NMSE (AUC:{nmse_auc:.2f})\", line=dict(color=\"steelblue\", width=2))\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=500, height=500,\n",
    "    xaxis_title = \"Signal efficiency\",\n",
    "    yaxis_title = \"Background Rejection\",\n",
    "    margin={'l': 60, 'b': 60, 't': 40, 'r': 0},\n",
    "    legend = dict(x=0.1, y=0.05,\n",
    "        traceorder='normal',\n",
    "        font=dict(size=15)),\n",
    "    title_text=\"ROC curves\"\n",
    ")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "#fig.write_image(\"ROC2jet.png\")\n",
    "fig.show('vscode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
