{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import numpy as np\n",
    "\n",
    "class DenseTied(tfkl.Layer):\n",
    "    def __init__(self, units,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 tied_to=None,\n",
    "                 **kwargs):\n",
    "        self.tied_to = tied_to\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tfk.activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = tfk.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tfk.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = tfk.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = tfk.regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = tfk.regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = tfk.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = tfk.constraints.get(bias_constraint)\n",
    "        self.input_spec = tfkl.InputSpec(min_ndim=2)\n",
    "        self.supports_masking = True\n",
    "                \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        if self.tied_to is not None:\n",
    "            self.kernel = tf.transpose(self.tied_to.kernel)\n",
    "            self._non_trainable_weights.append(self.kernel)\n",
    "        else:\n",
    "            self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
    "                                          initializer=self.kernel_initializer,\n",
    "                                          name='kernel',\n",
    "                                          regularizer=self.kernel_regularizer,\n",
    "                                          constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.units,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        #self.input_spec = tfkl.InputSpec(min_ndim=2, axes={-1: input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) >= 2\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[-1] = self.units\n",
    "        return tuple(output_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.matmul(inputs, self.kernel)\n",
    "        if self.use_bias:\n",
    "            output = tf.nn.bias_add(output, self.bias, data_format='N..C')\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        return output\n",
    "\n",
    "class DenseEncoder(tfkl.Layer):\n",
    "    \"\"\"Fully connected encoder made of 'Dense' layers.\"\"\"\n",
    "    def __init__(self,\n",
    "                 encoding_dim,\n",
    "                 units_list,\n",
    "                 hidden_activation,\n",
    "                 output_activation,\n",
    "                 weight_reg=None,\n",
    "                 bias_reg=None,\n",
    "                 output_reg=None,\n",
    "                 dtype=None,\n",
    "                 name=None):\n",
    "        \"\"\"Crates a DenseEncoder object.\n",
    "\n",
    "        Args:\n",
    "          encoding_dim: The number of nodes in the encoder output.\n",
    "          unitsl_list: List of integers. For every list element a Dense layer\n",
    "             will be crated and the number of nodes will be set to the value \n",
    "             of the element\n",
    "          hidden_activation: The activation funtion used for all the layers \n",
    "            apart from the output layer.\n",
    "          output_activation: The activation functiun used for the output layer\n",
    "          weight_reg: 'kernel_regularizer' of all layers.\n",
    "          bias_reg: 'bias_regularizer' of all layers.\n",
    "          output_reg: 'activity_regularizer' for all layers.\n",
    "          dtype: Data type, this argument is passed to the parent 'Layer' \n",
    "            class constructor\n",
    "          name: Object name, string to be passed to the parent class \n",
    "            constructor\n",
    "        \"\"\"\n",
    "        super(DenseEncoder, self).__init__(name=name, dtype=dtype)\n",
    "        # Create the list of the hidden layers\n",
    "        self.hidden_layers = [\n",
    "            tfkl.Dense(units, activation=hidden_activation, dtype=dtype,\n",
    "                       kernel_regularizer=weight_reg,\n",
    "                       bias_regularizer=bias_reg,\n",
    "                       activity_regularizer=output_reg) \n",
    "            for units \n",
    "            in units_list]\n",
    "        \n",
    "        # Creates the output layer\n",
    "        self.output_layer = tfkl.Dense(encoding_dim, dtype=dtype,\n",
    "                                       activation=output_activation,\n",
    "                                       kernel_regularizer=weight_reg,\n",
    "                                       bias_regularizer=bias_reg,\n",
    "                                       activity_regularizer=output_reg)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Runs the inputs through all of encoder layers\"\"\"\n",
    "        activation = reduce(lambda x, layer: layer(x), self.hidden_layers, \n",
    "                            inputs)\n",
    "        return self.output_layer(activation)\n",
    "\n",
    "\n",
    "class DenseDecoder(tfkl.Layer):\n",
    "    \"\"\"Fully connected decoders made of 'Dense' layers.\"\"\"\n",
    "    def __init__(self,\n",
    "                 output_dim,\n",
    "                 units_list,\n",
    "                 hidden_activation,\n",
    "                 output_activation,\n",
    "                 encoder_tied=None,\n",
    "                 weight_reg=None,\n",
    "                 bias_reg=None,\n",
    "                 output_reg=None,\n",
    "                 dtype=None,\n",
    "                 name=None):\n",
    "        \"\"\"Crates a DenseDecoder object.\n",
    "\n",
    "        Args:\n",
    "          encoding_dim: The number of nodes in the decoder output.\n",
    "          unitsl_list: List of integers. For every list element a Dense layer\n",
    "             will be crated and the number of nodes will be set to the value \n",
    "             of the element\n",
    "          hidden_activation: The activation funtion used for all the layers \n",
    "            apart from the output layer.\n",
    "          output_activation: The activation functiun used for the output layer\n",
    "          weight_reg: 'kernel_regularizer' of all layers.\n",
    "          bias_reg: 'bias_regularizer' of all layers.\n",
    "          output_reg: 'activity_regularizer' for all layers.\n",
    "          dtype: Data type, this argument is passed to the parent 'Layer' \n",
    "            class constructor\n",
    "          name: Object name, string to be passed to the parent class \n",
    "            constructor\n",
    "        \"\"\"\n",
    "        super(DenseDecoder, self).__init__(name=name, dtype=dtype)\n",
    "        if not encoder_tied:\n",
    "          # Creates the list of hidden layers \n",
    "          self.hidden_layers = [\n",
    "              tfkl.Dense(units, activation=hidden_activation, dtype=dtype,\n",
    "                        kernel_regularizer=weight_reg,\n",
    "                        bias_regularizer=bias_reg,\n",
    "                        activity_regularizer=output_reg) \n",
    "              for units \n",
    "              in units_list] \n",
    "\n",
    "          # Creates the output layer\n",
    "          self.output_layer = tfkl.Dense(output_dim, dtype=dtype,\n",
    "                                        activation=output_activation,\n",
    "                                        kernel_regularizer=weight_reg,\n",
    "                                        bias_regularizer=bias_reg,\n",
    "                                        activity_regularizer=output_reg)\n",
    "        else:\n",
    "          # Creates the list of hidden layers \n",
    "          n_layers = len(units_list)\n",
    "          self.hidden_layers = [\n",
    "              DenseTied(units, activation=hidden_activation, dtype=dtype,\n",
    "                        kernel_regularizer=weight_reg,\n",
    "                        bias_regularizer=bias_reg,\n",
    "                        activity_regularizer=output_reg,\n",
    "                        tied_to=encoder_tied.hidden_layers[n_layers-i-1]\n",
    "                                if i != n_layers-1 else encoder_tied.output_layer) \n",
    "              for i, units \n",
    "              in enumerate(units_list)] \n",
    "\n",
    "          # Creates the output layer\n",
    "          self.output_layer = DenseTied(output_dim, dtype=dtype,\n",
    "                                        activation=output_activation,\n",
    "                                        kernel_regularizer=weight_reg,\n",
    "                                        bias_regularizer=bias_reg,\n",
    "                                        activity_regularizer=output_reg,\n",
    "                                        tied_to=encoder_tied.hidden_layers[0])\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Run the inputs through all of the decoder layers.\"\"\"\n",
    "        activation = reduce(lambda x, layer: layer(x), self.hidden_layers, \n",
    "                            inputs)\n",
    "        return self.output_layer(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pae.models.autoencoder import DenseAutoencoder, DenseAutoencoderTied\n",
    "from pae.models.flows import MAF\n",
    "from pae.models.nn import PaeBuilder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = PaeBuilder()\n",
    "\n",
    "ae_config = {\n",
    "    'input_dim':10, \n",
    "    'encoding_dim':3, \n",
    "    'units':[8, 5],\n",
    "    'weight_reg':tfk.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    'output_activation':tf.nn.sigmoid\n",
    "}\n",
    "nf_config = {\n",
    "    'n_dims':3, \n",
    "    'n_layers':2, \n",
    "    'units':[32 for _ in range(4)]\n",
    "}\n",
    "optimizer_ae = {\n",
    "    'learning_rate': 0.001\n",
    "}\n",
    "optimizer_nf = {\n",
    "    'learning_rate': 0.005\n",
    "}\n",
    "\n",
    "builder.make_ae_model(DenseAutoencoderTied, ae_config)\n",
    "builder.make_ae_optimizer(tfk.optimizers.Adam, optimizer_ae)\n",
    "builder.make_nf_model(MAF, nf_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_nf)\n",
    "builder.compile_ae()\n",
    "builder.compile_nf()\n",
    "pae = builder.pae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':120,\n",
    "    \"verbose\":0\n",
    "}\n",
    "\n",
    "nf_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':80,\n",
    "    \"verbose\":0\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.random.normal(0, 1, (1000,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    %time pae.fit(dataset,None,ae_train,nf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in pae.ae.encoder.hidden_layers:\n",
    "    print(l.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70f45a738872f66498ef9def3ce24bedd18274b41618f938c7df5c328e4074a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
