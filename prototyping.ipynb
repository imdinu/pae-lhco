{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from models.autoencoder import DenseAutoencoder\n",
    "from models.flows import MAF\n",
    "from models.nn import PaeBuilder\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "print(device_lib.list_local_devices())\n",
    "#tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders.LHCO import LhcoRnDLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "scaler = QuantileTransformer(output_distribution='uniform')\n",
    "#scaler = MinMaxScaler()\n",
    "files = {\n",
    "    'bkg':'../data/RnD_bkg_HLF.h5',\n",
    "    'sig1':'../data/RnD_sig1_HLF.h5',\n",
    "    'sig2':'../data/RnD_sig2_HLF.h5'\n",
    "}\n",
    "\n",
    "train_fractions = {\n",
    "    'bkg':1\n",
    "}\n",
    "\n",
    "test_fractions = {\n",
    "    'bkg':.5,\n",
    "    'sig1':.5\n",
    "}\n",
    "\n",
    "loader = LhcoRnDLoader(files, 'all', scaler)\n",
    "loader.preprocessing('bkg')\n",
    "train = loader.make_train_val(250_000, train_fractions, val_split=.2)\n",
    "test = loader.make_test(100_000, test_fractions, replace=False)\n",
    "\n",
    "dataset = {**train, **test}\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['mjj_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import feature_plots\n",
    "\n",
    "feature_plots(dataset['x_train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_plots(dataset['x_test'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "GMM = GaussianMixture\n",
    "\n",
    "%time gmm = GMM(n_components=350, covariance_type='full').fit(dataset[\"mjj_train\"].reshape(-1,1))\n",
    "plt.figure(figsize=(12,8))\n",
    "_, b, _ = plt.hist(dataset[\"mjj_train\"], bins=50, label='mjj true', alpha=.5, density=True)\n",
    "sample = gmm.sample(dataset[\"mjj_train\"].shape[0])\n",
    "plt.hist(sample[0], bins=b, label='mjj GMM', alpha=.5, density=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = gmm.score_samples(dataset[\"mjj_train\"].reshape(-1,1))\n",
    "weights2_valid = gmm.score_samples(dataset[\"mjj_valid\"].reshape(-1,1))\n",
    "plt.figure(figsize=(12,8))\n",
    "_, b, _ = plt.hist(dataset[\"mjj_train\"], bins=50, label='mjj weighted', alpha=.5, weights=np.exp(weights2))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(dataset[\"mjj_train\"], 1/np.exp(weights2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfkl = tfk.layers\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.autoencoder import DenseAutoencoder\n",
    "from models.flows import MAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "builder = PaeBuilder()\n",
    "\n",
    "ae_config = {\n",
    "    'input_dim':47, \n",
    "    'encoding_dim':10, \n",
    "    'units_list':[30, 20, 15],\n",
    "    'weight_reg':tfk.regularizers.l1(1e-6),\n",
    "    'output_activation':tf.nn.sigmoid\n",
    "}\n",
    "nf_config = {\n",
    "    'n_dims':10, \n",
    "    'n_layers':5, \n",
    "    'units':[32 for i in range(4)]\n",
    "}\n",
    "optimizer_ae = {\n",
    "    'lr': 0.05\n",
    "}\n",
    "optimizer_nf = {\n",
    "    'lr': 0.005\n",
    "}\n",
    "\n",
    "builder.make_ae_model(DenseAutoencoder, ae_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_ae)\n",
    "builder.make_nf_model(MAF, nf_config)\n",
    "builder.make_nf_optimizer(tfk.optimizers.Adam, optimizer_nf)\n",
    "builder.compile_ae()\n",
    "builder.compile_nf()\n",
    "pae = builder.pae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "ae_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':180,\n",
    "    'sample_weight':1/np.exp(weights2),\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"],1/np.exp(weights2_valid)),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=10,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "\n",
    "nf_train ={\n",
    "    'batch_size':200,\n",
    "    'epochs':100,\n",
    "    'validation_data':(dataset[\"x_valid\"],dataset[\"x_valid\"]),\n",
    "    'callbacks':tfk.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    )\n",
    "}\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    %time pae.fit(dataset[\"x_train\"],ae_train,nf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.plotting import loss_plot, latent_space_plot, mjj_cut_plot, \\\n",
    "                           sculpting_plot, roc_plot\n",
    "\n",
    "loss_plot(pae.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_true = pae.ae.encode(dataset['x_train'])\n",
    "z_sample = pae.nf.sample(dataset['x_train'].shape[0])\n",
    "\n",
    "latent_space_plot(z_true, z_sample, save_path='plots/latent_space.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimal_grid(n):\n",
    "    rows = np.floor(np.sqrt(n))\n",
    "    residual = 1 if n%rows != 0 else 0\n",
    "    cols = n//rows + residual\n",
    "    return int(rows), int(cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mse = pae.reco_error(dataset['x_train'])\n",
    "pae.compute_implicit_sigma(dataset['x_valid'])\n",
    "ascore = -pae.anomaly_score(dataset['x_train'])\n",
    "\n",
    "mjj_cut_plot(mse, dataset['mjj_train'], prc=80, score_name='MSE')#, save_path='./plots/mse_cut.png')\n",
    "mjj_cut_plot(ascore, dataset['mjj_train'], prc=80, score_name='NLL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sculpting_plot(ano_scores, mjj, \n",
    "                   max_prc: int = 90, \n",
    "                   bins: int = 60,\n",
    "                   save_path: str = None):\n",
    "    from scipy.spatial.distance import jensenshannon\n",
    "    sculpting_plots = {}\n",
    "    for label, score in ano_scores.items():\n",
    "        n_full, b = np.histogram(mjj, bins=bins, density=True)\n",
    "        js_div = {}\n",
    "        for prc in range(1, max_prc+1):\n",
    "            x_prc = np.percentile(score, prc)\n",
    "            i_prc = np.where(score >= x_prc)[0]\n",
    "            n_prc, _ = np.histogram(mjj[i_prc], bins=b, density=True)\n",
    "            js_div[prc] = jensenshannon(n_full,n_prc)\n",
    "        sculpting_plots[label]=js_div\n",
    "        \n",
    "    plt.figure(figsize=(10,6))\n",
    "    for label, js_div in sculpting_plots.items():\n",
    "        plt.plot(js_div.keys(), js_div.values(), label=label)\n",
    "    plt.ylabel('JS-divergence')\n",
    "    plt.xlabel('Percentile cut')\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.title('Mass sculpting')\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    return sculpting_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_scores = {\n",
    "    'MSE': mse,\n",
    "    'NLL': ascore\n",
    "}\n",
    "\n",
    "jss = sculpting_plot(ano_scores, dataset['mjj_train'], max_prc=99, save_path='./plots/mass_sculpting.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(jss['NLL'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy = np.diff(list(jss['MSE'].values()))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(list(jss['MSE'].keys())[1:], dy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binarize(label):\n",
    "    return 1 if label == 'sig1' else 0\n",
    "\n",
    "mse_test = pae.reco_error(dataset['x_test'])\n",
    "ascore_test = -pae.anomaly_score(dataset['x_test'])\n",
    "targets = np.array(list(map(binarize, dataset['labels'])))\n",
    "\n",
    "scores = {\n",
    "    'NLL':ascore_test,\n",
    "    'MSE':mse_test\n",
    "}\n",
    "roc_plot(targets,scores,save_path='./plots/roc_50prc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjj_cut_plot(ano_score, mjj, \n",
    "                 prc: int = 75, \n",
    "                 bins: int = 60, \n",
    "                 x_min_prc: float = 0.5,\n",
    "                 x_max_prc: float = 99.5,\n",
    "                 score_name: str = 'anomaly score', \n",
    "                 save_path: str = None):\n",
    "    \n",
    "    x_min = np.percentile(ano_score, x_min_prc)\n",
    "    x_max = np.percentile(ano_score, x_max_prc)\n",
    "    x_prc = np.percentile(ano_score, prc)\n",
    "    i_prc = np.where(ano_score >= x_prc)[0]\n",
    "    not_i = np.where(ano_score <= x_prc)[0]\n",
    "\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(ano_score, bins=bins, density=True, alpha=.8, \n",
    "             label='Test dataset')\n",
    "    plt.xlim(x_min,x_max)\n",
    "    plt.axvline(x_prc, color='red', label=f'{prc}''$^{th}$ percentile')\n",
    "    plt.legend()\n",
    "    plt.xlabel(f'{score_name}')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    n_bkg, b, _ = plt.hist(mjj, bins=bins, density=True, alpha=.5, \n",
    "                       label='Full test datset')\n",
    "    n_sig, _, _ = plt.hist(mjj[i_prc], bins=b, density=True, alpha=.5, \n",
    "                       label=f'{prc}''$^{th}$'f' {score_name} percentile+')\n",
    "    plt.xlabel('$m_{jj}$')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    return mjj.ravel(), mjj[i_prc].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fractions = {\n",
    "    'bkg':.999,\n",
    "    'sig1':.0001\n",
    "}\n",
    "test2 = loader.make_test(500_000, test_fractions, replace=False)\n",
    "\n",
    "ascore_test = -pae.anomaly_score(test2['x_test'])\n",
    "mse_test = pae.reco_error(test2['x_test'])\n",
    "bkg, data = mjj_cut_plot(ascore_test, test2['mjj_test'], prc=0, score_name='NLL', bins=100, save_path='./plots/cut_01prc.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg2, data2 = mjj_cut_plot(ascore_test, test2['mjj_test'], prc=99, score_name='NLL', bins=100, save_path='./plots/cut_01prc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg.shape[0]/data.shape[0]\n",
    "weights = np.repeat(1/(bkg.shape[0]/data.shape[0]),bkg.shape[0])\n",
    "weights_k = np.repeat(1/(data.shape[0]/data2.shape[0]),data.shape[0]) #data.shape[0]/data2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBumpHunter as BH\n",
    "\n",
    "hunter = BH.BumpHunter(rang=(3000,4500),\n",
    "                       width_min=2,\n",
    "                       width_max=5,\n",
    "                       width_step=1,\n",
    "                       scan_step=1,\n",
    "                       Npe=10000,\n",
    "                       Nworker=1,\n",
    "                       seed=666,\n",
    "                       weights=weights_k\n",
    "                    )\n",
    "\n",
    "# x_prc_50 = np.percentile(ascore_test, 50)\n",
    "\n",
    "# high_prc = np.where(ascore_test >= x_prc_50)\n",
    "# low_prc = np.where(ascore_test <= x_prc_50)\n",
    "\n",
    "# data, bkg = test2['excl_test'][high_prc][:,0], test2['excl_test'][low_prc][:,0]\n",
    "\n",
    "%time hunter.BumpScan(data2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hunter.PlotBump(data2,data)#, filename='./plots/bump_01prc.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hunter.PrintBumpTrue(data2,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array(list(map(binarize, test2['labels'])))\n",
    "\n",
    "scores = {\n",
    "    'NLL':ascore_test\n",
    "}\n",
    "roc_plot(targets,scores,save_path='./plots/roc_1prc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}